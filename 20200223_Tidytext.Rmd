---
title: "Tidy text"
author: "Alison E. Turnbull"
date: "3/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages, include=FALSE}
library(tidyverse)
library(here)
library(ggplot2)
library(knitr)
library(kableExtra)
library(forcats)
library(stringr)
library(tidytext)
library(textdata)
```

#### Load data
```{r load data}
data <- read_csv(here::here("data", "20200218_COPD Qualanalysis data.csv"), col_types = cols())
```

### Tokenization of comments
```{r tokenization}
  t_data<- data %>%
              mutate(gold_doc_comment= ifelse(!is.na(comment_cat), "Yes", "No")) %>%
              filter(gold_doc_comment=="Yes") %>%
              select(uid, comment) %>%
              unnest_tokens(word, comment)
```

### Remove stop words
```{r stopwords, message=FALSE}
  custom_stop_words <- bind_rows(tibble(word = c("patient", "mother", "don"), 
                                          lexicon = c("custom")), 
                               stop_words)


  t_data<-t_data %>% 
      anti_join(stop_words) %>%
      anti_join(custom_stop_words)
```

### How long were most people's comments?
```{r length of comment}
by_uid<-t_data %>%
         group_by(uid) %>%
            count(uid)

ggplot(by_uid, aes(x=n)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "How many words (excluding stop words) are in open-ended responses?", x="Number of words", y="Number of responses") +
                      theme_bw()
```




### Looking at the most common words in comments about doctors (excluding stop words)
```{r common words}

  t_data %>%
      count(word, sort = TRUE) %>%
        filter(n >5) %>%
          mutate(word = reorder(word, n )) %>%
            ggplot(aes(word, n)) +
              geom_col() + 
                xlab(NULL) + 
                labs(title = "Words appearing >5 times in open-ended responses", y ="How many times this word appears in responses") +
                  coord_flip() +
                    theme_bw()

```

### Afinn lexicon 
```{r AFINN, message=FALSE}
afinn<-t_data %>%
  inner_join(get_sentiments("afinn")) %>%
    group_by(uid) %>%
        summarise(sentiment = sum(value)) %>%
            mutate(method = "AFINN")


ggplot(afinn, aes(x=sentiment)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "Histogram of Afinn sentiment total", x="Sentiment", y="Number of responses") +
                      theme_bw()
```

### Bing lexicon 
```{r Bing, message=FALSE}
bing<-t_data %>%
  inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing") %>%
      count(method, uid, sentiment) %>%
        spread(sentiment, n, fill=0) %>%
          mutate(total_sentiments = positive+negative) %>%
            mutate(net_sentiment = positive - negative)

ggplot(bing, aes(x=net_sentiment)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "Histogram of Net Bing Sentiment", x=" Net Sentiment", y="Number of responses") +
                      theme_bw()

```

### nrc lexicon 
```{r Bing}
nrc<-t_data %>%
  inner_join(get_sentiments("nrc")) %>%
    mutate(method = "NRC") %>%
      filter(sentiment %in% c("positive", "negative")) %>%
        count(method, uid, sentiment) %>%
          spread(sentiment, n, fill=0) %>%
            mutate(total_sentiments = positive+negative) %>%
              mutate(net_sentiment = positive - negative)
          

ggplot(nrc, aes(x=net_sentiment)) + geom_histogram(color="black", fill="gray", binwidth = 1) +
                labs(title = "Histogram of Net NRC Sentiment", x=" Net Sentiment", y="Number of responses") +
                      theme_bw()

```

## Looking at the top negative and positive words

```{r  top_neg_pos_words, message=FALSE}
afinn_word_counts <- t_data %>%
    count(word, sort = TRUE) %>%
    inner_join(get_sentiments("afinn")) %>%
    ungroup()

bing_word_counts <- t_data %>%
    inner_join(get_sentiments("bing")) %>%
    count(word, sentiment, sort = TRUE) %>%
    ungroup()

nrc_word_counts <- t_data %>%
    inner_join(get_sentiments("nrc")) %>%
    count(word, sentiment, sort = TRUE) %>%
    ungroup()


afinn_word_counts %>%
  mutate(sentiment=ifelse(value<0, "Negative", "Positive")) %>%
  group_by(sentiment) %>%
  top_n(5) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to AFINN sentiment",
       x = NULL) +
  coord_flip() +
  theme_bw()


bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to BING sentiment",
       x = NULL) +
  coord_flip() +
  theme_bw()

nrc_word_counts %>%
  filter(sentiment==c("negative", "positive")) %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to NRC sentiment",
       x = NULL) +
  coord_flip() + 
  theme_bw()

```




## Looking at correlations between sentiment measures from the 3 lexicons - scatter plots

```{r lexicon_correlations}
nrc<-nrc %>%
    mutate(nrc_net_sentiment=net_sentiment)

bing<-bing %>%
    mutate(bing_net_sentiment=net_sentiment)



## Creating a dataframe with just uid, sentiment, and the gold standard
all_sentiments<-nrc %>%
              select(uid, nrc_net_sentiment) %>%
                full_join(bing, by="uid") %>%
                  select(uid, nrc_net_sentiment, bing_net_sentiment) %>%
                    full_join(afinn, by="uid") %>%
                      select(-method) %>%
                        rename(afinn_sentiment=sentiment)


## Gold standard for the presence of a comment about doctors connected to sentiments
doc_comments<-data %>%
      mutate(gold_doc_comment= ifelse(!is.na(comment_cat), "Yes", "No")) %>%
        filter(gold_doc_comment=="Yes") %>%
          select(uid, ed, age, ethn, race, sex, vent, relat, region, arm, rasch_score_total, trust_score, comment, comment_cat, sentim_final) %>% 
            left_join(all_sentiments, by="uid")


## How many missing sentiment values? 
doc_comments %>%
    select(afinn_sentiment, bing_net_sentiment, nrc_net_sentiment) %>%
      summarise_all(funs(sum(is.na(.))))  ##Afinn = 34, Bing = 29, and NRC=17 missing

            
RNC_Bing_plot<-ggplot(doc_comments, aes(x=nrc_net_sentiment, y=bing_net_sentiment, color=sentim_final)) + 
            geom_point() + 
              geom_jitter() + 
                geom_hline(yintercept=0) +
                geom_vline(xintercept = 0) +
                labs(title = "Comparing Sentiment with NRC and Bing lexicons", x="NRC", y="Bing") + 
                  theme_bw()

RNC_afinn_plot<-ggplot(doc_comments, aes(x=nrc_net_sentiment, y=afinn_sentiment, color=sentim_final)) + 
            geom_point() + 
              geom_jitter() + 
                geom_hline(yintercept=0) +
                geom_vline(xintercept = 0) +
                labs(title = "Comparing Sentiment with NRC and AFINN lexicons", x="NRC", y="AFINN") + 
                  theme_bw()

AFINN_Bing_plot<-ggplot(doc_comments, aes(x=afinn_sentiment, y=bing_net_sentiment, color=sentim_final)) + 
            geom_point() + 
              geom_hline(yintercept=0) +
              geom_vline(xintercept = 0) +
              geom_jitter() + 
                labs(title = "Comparing Sentiment with AFINN and Bing lexicons", x="AFINN", y="Bing") + 
                  theme_bw()

RNC_Bing_plot
RNC_afinn_plot
AFINN_Bing_plot
```

### Abandoning this line of investigation.  None of these lexicons did a great job of describing the sentiment in comments. 

## Moving on! 




